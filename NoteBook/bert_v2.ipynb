{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 1: **Load the Dataset**\n",
    "We‚Äôll start by loading the dataset from the CSV file (`smsDataLast.csv`) using `pandas`.\n",
    "\n",
    "### Explanation:\n",
    "- The dataset contains SMS messages and their corresponding categories (labels).\n",
    "- We‚Äôll use `pandas` to load the data into a DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Data/labeled_combined_sms_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message Content</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>is_important</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samba.</td>\n",
       "      <td>ÿ™ŸÖ ÿÆÿµŸÖ ŸÖÿ®ŸÑÿ∫ Ÿ•Ÿ†Ÿ´Ÿ†Ÿ† ŸÖŸÜ ÿ≠ÿ≥ÿßÿ® ******Ÿ§Ÿ•Ÿ¢Ÿ° ŸÅŸä Ÿ†Ÿ•-Ÿ†Ÿ•-...</td>\n",
       "      <td>['Money/Financial', 'Expense']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'amount': 'Ÿ•Ÿ†Ÿ´Ÿ†Ÿ†', 'type': 'expense', 'accoun...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607941</td>\n",
       "      <td>Your WhatsApp code is 614-968 but you can simp...</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>Dear Member, you have not redeemed any Neqaty ...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>ÿπÿ≤Ÿäÿ≤Ÿä ÿßŸÑÿπŸÖŸäŸÑÿå ŸÑŸÇÿØ ŸÖÿ± 17 ÿ¥Ÿáÿ± Ÿà ŸÑŸÖ ÿ™ŸÇŸÖ ÿ®ÿßŸä ÿπŸÖŸÑŸäÿ©...</td>\n",
       "      <td>['Notification', 'Promotion']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606006</td>\n",
       "      <td>BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sender                                    Message Content  \\\n",
       "0  samba.  ÿ™ŸÖ ÿÆÿµŸÖ ŸÖÿ®ŸÑÿ∫ Ÿ•Ÿ†Ÿ´Ÿ†Ÿ† ŸÖŸÜ ÿ≠ÿ≥ÿßÿ® ******Ÿ§Ÿ•Ÿ¢Ÿ° ŸÅŸä Ÿ†Ÿ•-Ÿ†Ÿ•-...   \n",
       "1  607941  Your WhatsApp code is 614-968 but you can simp...   \n",
       "2  neqaty  Dear Member, you have not redeemed any Neqaty ...   \n",
       "3  neqaty  ÿπÿ≤Ÿäÿ≤Ÿä ÿßŸÑÿπŸÖŸäŸÑÿå ŸÑŸÇÿØ ŸÖÿ± 17 ÿ¥Ÿáÿ± Ÿà ŸÑŸÖ ÿ™ŸÇŸÖ ÿ®ÿßŸä ÿπŸÖŸÑŸäÿ©...   \n",
       "4  606006  BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...   \n",
       "\n",
       "                  category_labels  is_important  is_spam  \\\n",
       "0  ['Money/Financial', 'Expense']             1        0   \n",
       "1                       ['Other']             0        0   \n",
       "2    ['Promotion', 'Advertising']             0        1   \n",
       "3   ['Notification', 'Promotion']             0        1   \n",
       "4    ['Promotion', 'Advertising']             0        1   \n",
       "\n",
       "                                        transactions dates  \n",
       "0  {'amount': 'Ÿ•Ÿ†Ÿ´Ÿ†Ÿ†', 'type': 'expense', 'accoun...   NaN  \n",
       "1                                                NaN   NaN  \n",
       "2                                                NaN   NaN  \n",
       "3                                                NaN   NaN  \n",
       "4                                                NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6996 entries, 0 to 6995\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Sender           6996 non-null   object\n",
      " 1   Message Content  6996 non-null   object\n",
      " 2   category_labels  6996 non-null   object\n",
      " 3   is_important     6996 non-null   int64 \n",
      " 4   is_spam          6996 non-null   int64 \n",
      " 5   transactions     3053 non-null   object\n",
      " 6   dates            484 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 382.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the columns and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_labels\n",
       "['Money/Financial', 'Expense']                       2219\n",
       "['Promotion', 'Advertising']                         1240\n",
       "['Other']                                             851\n",
       "['Notification', 'Other']                             361\n",
       "['Money/Financial', 'Expense', 'Notification']        346\n",
       "                                                     ... \n",
       "['Money/Financial', 'Notification', 'Government']       1\n",
       "['Money/Financial', 'Donation']                         1\n",
       "['Promotion', 'Investment']                             1\n",
       "['Money/Financial', 'Transaction']                      1\n",
       "['Promotion', 'Health', 'Education']                    1\n",
       "Name: count, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of categories\n",
    "df['category_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_labels = df['category_labels'].unique()\n",
    "# for label in unique_labels:\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 2: **Preprocess the Data**\n",
    "We‚Äôll preprocess the data to prepare it for training. This includes:\n",
    "- Mapping categories to numerical labels.\n",
    "- Splitting the data into training and testing sets.\n",
    "\n",
    "### Explanation:\n",
    "- Text classification requires numerical labels, so we‚Äôll convert the `Category` column to numerical values.\n",
    "- We‚Äôll split the data into training and testing sets (e.g., 80% training, 20% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category_labels from string to list\n",
    "df['category_labels'] = df['category_labels'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique labels\n",
    "all_labels = sorted(list(set(label for labels in df['category_labels'] for label in labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform category_labels into binary vectors\n",
    "binary_labels = mlb.fit_transform(df['category_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binary_labels'] = binary_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sender', 'Message Content', 'category_labels', 'is_important',\n",
       "       'is_spam', 'transactions', 'dates', 'binary_labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1765, random_state=42)  # 15% of original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 3: **Tokenize the Data**\n",
    "We‚Äôll tokenize the text data using the `AutoTokenizer` from Hugging Face‚Äôs `transformers` library.\n",
    "\n",
    "### Explanation:\n",
    "- Tokenization converts text into numerical input that the model can understand.\n",
    "- We‚Äôll use the `AutoTokenizer` for ModernBERT and ensure all sequences are padded/truncated to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Message Content\"], padding=\"max_length\", truncation=True, max_length=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization to the training and testing datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4896/4896 [00:00<00:00, 30568.42 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1050/1050 [00:00<00:00, 29084.60 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1050/1050 [00:00<00:00, 29459.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized example: {'Sender': 'samba.', 'Message Content': 'ÿßŸÑÿ±ÿ¨ÿßÿ° ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ±ŸÖÿ≤ ÿßŸÑŸÖÿ±Ÿàÿ± ÿ±ŸÇŸÖ   5511\\r\\n ŸÑŸÑÿØÿÆŸàŸÑ ÿßŸÑŸâ ÿÆÿØŸÖÿßÿ™ ÿ≥ÿßŸÖÿ®ÿßŸÖŸàÿ®ÿßŸäŸÑ', 'category_labels': ['Other'], 'is_important': 0, 'is_spam': 0, 'transactions': None, 'dates': None, 'binary_labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], '__index_level_0__': 1685, 'input_ids': [50281, 7427, 6900, 23072, 10714, 96, 32262, 113, 8181, 28337, 9211, 30901, 39410, 5843, 29620, 30331, 6900, 39727, 39410, 14062, 5843, 50275, 2417, 883, 2379, 23630, 4467, 9211, 28337, 41147, 9445, 25378, 45232, 9211, 5843, 24823, 34341, 30901, 13621, 30901, 6534, 13621, 3142, 6463, 4467, 50282, 50283, 50283, 50283, 50283, 50283, 50283], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Check the tokenized output for the first example\n",
    "print(\"Tokenized example:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: **Test the Model on a Single Row**\n",
    "Before training, we‚Äôll test the model on a single row to ensure it works.\n",
    "\n",
    "### Explanation:\n",
    "- We‚Äôll load the ModernBERT model and pass a single tokenized input to it.\n",
    "- This helps verify that the model and tokenizer are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    num_labels=len(all_labels),  # Number of unique labels\n",
    "    problem_type=\"multi_label_classification\"  # Specify multi-label classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Extract the first row\n",
    "row = df.loc[0]\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(\n",
    "    row[\"Message Content\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda-12.2'\n"
     ]
    }
   ],
   "source": [
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Category Labels (multi-label classification)\n",
    "probs = torch.sigmoid(logits)\n",
    "threshold = 0.5\n",
    "binary_preds = (probs > threshold).int().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map binary predictions to label names\n",
    "predicted_labels = [all_labels[i] for i, val in enumerate(binary_preds[0]) if val == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict is_spam and is_important (binary classification)\n",
    "is_spam_prob = torch.sigmoid(logits[:, 0]).item()\n",
    "is_spam_pred = 1 if is_spam_prob > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_important_prob = torch.sigmoid(logits[:, 1]).item()\n",
    "is_important_pred = 1 if is_important_prob > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message Content: ÿ™ŸÖ ÿÆÿµŸÖ ŸÖÿ®ŸÑÿ∫ Ÿ•Ÿ†Ÿ´Ÿ†Ÿ† ŸÖŸÜ ÿ≠ÿ≥ÿßÿ® ******Ÿ§Ÿ•Ÿ¢Ÿ° ŸÅŸä Ÿ†Ÿ•-Ÿ†Ÿ•-Ÿ¢Ÿ†Ÿ°Ÿ• Ÿ¢Ÿ†:Ÿ£Ÿ©ŸÖÿ≥ÿßÿ°Ÿã\n",
      "\n",
      "True Category Labels: ['Money/Financial', 'Expense']\n",
      "Predicted Category Labels: ['Donation', 'Education', 'Emergency', 'Event', 'Expense', 'Health', 'Income', 'Promotion', 'Security', 'Test/Exam', 'Transaction', 'Transfer', 'Travel']\n",
      "\n",
      "True is_spam: 0\n",
      "Predicted is_spam: 0\n",
      "\n",
      "True is_important: 1\n",
      "Predicted is_important: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMessage Content:\", row[\"Message Content\"])\n",
    "print(\"\\nTrue Category Labels:\", row[\"category_labels\"])\n",
    "print(\"Predicted Category Labels:\", predicted_labels)\n",
    "print(\"\\nTrue is_spam:\", row[\"is_spam\"])\n",
    "print(\"Predicted is_spam:\", is_spam_pred)\n",
    "print(\"\\nTrue is_important:\", row[\"is_important\"])\n",
    "print(\"Predicted is_important:\", is_important_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: **Train the Model**\n",
    "We‚Äôll train the model using the `Trainer` API from Hugging Face.\n",
    "\n",
    "### Explanation:\n",
    "- The `Trainer` API simplifies the training process by handling training loops, evaluation, and logging.\n",
    "- We‚Äôll define training arguments (e.g., learning rate, batch size) and train the model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary_labels to PyTorch tensors of type Float\n",
    "train_labels = torch.tensor(train_df['binary_labels'].tolist(), dtype=torch.float)\n",
    "val_labels = torch.tensor(val_df['binary_labels'].tolist(), dtype=torch.float)\n",
    "test_labels = torch.tensor(test_df['binary_labels'].tolist(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary labels to the datasets\n",
    "train_dataset = train_dataset.add_column('labels', train_labels.tolist())\n",
    "val_dataset = val_dataset.add_column('labels', val_labels.tolist())\n",
    "test_dataset = test_dataset.add_column('labels', test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    num_labels=len(all_labels),  # Number of unique labels\n",
    "    problem_type=\"multi_label_classification\"  # Specify multi-label classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/transformers/training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    logging_strategy=\"epoch\",     # Log metrics at the end of each epoch\n",
    "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",         # Directory for logs\n",
    "    report_to=\"all\",              # Log to all available trackers (e.g., TensorBoard, W&B)\n",
    "    load_best_model_at_end=True,  # Required for EarlyStoppingCallback\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss to determine the best model\n",
    "    greater_is_better=False,      # Lower validation loss is better\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop if validation loss doesn't improve for 3 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2448' max='6120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2448/6120 1:11:02 < 1:46:38, 0.57 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.071041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.049210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.049279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.047333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.042408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.047730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.052532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.051579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2448, training_loss=0.02978924043427885, metrics={'train_runtime': 4264.3697, 'train_samples_per_second': 22.962, 'train_steps_per_second': 1.435, 'total_flos': 1355750853949440.0, 'train_loss': 0.02978924043427885, 'epoch': 8.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 6: **Evaluate the Model**\n",
    "After training, we‚Äôll evaluate the model on the test set.\n",
    "\n",
    "### Explanation:\n",
    "- We‚Äôll use the `Trainer` API to evaluate the model‚Äôs performance on the test dataset.\n",
    "- Metrics like accuracy, precision, recall, and F1 score can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation results: {'eval_loss': 0.04240785166621208, 'eval_runtime': 24.1587, 'eval_samples_per_second': 43.463, 'eval_steps_per_second': 5.464, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate(val_dataset)\n",
    "print(\"Test set evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the model\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits to probabilities (sigmoid for multi-label classification)\n",
    "pred_probs = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a threshold (e.g., 0.5) to convert probabilities to binary labels\n",
    "pred_labels = (pred_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the true labels\n",
    "true_labels = test_df['binary_labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Advertising       0.96      0.83      0.89       258\n",
      "    Appointment       1.00      0.59      0.74        22\n",
      "       Delivery       0.00      0.00      0.00         0\n",
      "       Donation       0.00      0.00      0.00         0\n",
      "      Education       0.60      0.27      0.38        22\n",
      "      Emergency       0.00      0.00      0.00         1\n",
      "          Event       0.00      0.00      0.00         1\n",
      "        Expense       0.99      0.97      0.98       408\n",
      "     Government       0.78      0.33      0.47        42\n",
      "         Health       0.71      0.58      0.64        26\n",
      "         Income       1.00      1.00      1.00        49\n",
      "     Investment       0.00      0.00      0.00         1\n",
      "    Investments       0.00      0.00      0.00         2\n",
      "          Loans       0.00      0.00      0.00         0\n",
      "Money/Financial       0.98      0.99      0.98       481\n",
      "   Notification       0.85      0.84      0.85       302\n",
      "          Other       0.83      0.81      0.82       171\n",
      "      Promotion       0.95      0.91      0.93       258\n",
      "        Savings       1.00      0.50      0.67         2\n",
      "       Security       1.00      0.22      0.36         9\n",
      "      Test/Exam       0.00      0.00      0.00         1\n",
      "    Transaction       0.00      0.00      0.00         0\n",
      "       Transfer       0.00      0.00      0.00         2\n",
      "         Travel       0.50      0.17      0.25         6\n",
      "        Warning       0.00      0.00      0.00         0\n",
      "\n",
      "      micro avg       0.94      0.88      0.91      2064\n",
      "      macro avg       0.49      0.36      0.40      2064\n",
      "   weighted avg       0.93      0.88      0.90      2064\n",
      "    samples avg       0.91      0.88      0.88      2064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(true_labels, pred_labels, average='micro')\n",
    "recall = recall_score(true_labels, pred_labels, average='micro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision: 0.9370\n",
      " Recall: 0.8789\n",
      " F1 Score: 0.9070\n"
     ]
    }
   ],
   "source": [
    "print(f\" Precision: {precision:.4f}\")\n",
    "print(f\" Recall: {recall:.4f}\")\n",
    "print(f\" F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 7: **Save the Model**\n",
    "We‚Äôll save the fine-tuned model for future use.\n",
    "\n",
    "### Explanation:\n",
    "- Saving the model allows us to reuse it without retraining.\n",
    "- We‚Äôll save both the model and tokenizer to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Models/fine-tuned-modernbert_multilabel/tokenizer_config.json',\n",
       " '../Models/fine-tuned-modernbert_multilabel/special_tokens_map.json',\n",
       " '../Models/fine-tuned-modernbert_multilabel/tokenizer.json')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"../Models/fine-tuned-modernbert_multilabel\")\n",
    "tokenizer.save_pretrained(\"../Models/fine-tuned-modernbert_multilabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 8: **Load the Fine-Tuned Model**\n",
    "To load the fine-tuned model later:\n",
    "\n",
    "### Explanation:\n",
    "- We‚Äôll load the saved model and tokenizer for inference or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../Models/fine-tuned-modernbert_multilabel\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../Models/fine-tuned-modernbert_multilabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model labels: ['LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_3', 'LABEL_4', 'LABEL_5', 'LABEL_6', 'LABEL_7', 'LABEL_8', 'LABEL_9', 'LABEL_10', 'LABEL_11', 'LABEL_12', 'LABEL_13', 'LABEL_14', 'LABEL_15', 'LABEL_16', 'LABEL_17', 'LABEL_18', 'LABEL_19', 'LABEL_20', 'LABEL_21', 'LABEL_22', 'LABEL_23', 'LABEL_24']\n"
     ]
    }
   ],
   "source": [
    "config = model.config\n",
    "\n",
    "if hasattr(config, \"id2label\"):\n",
    "    labels = list(config.id2label.values())\n",
    "    print(\"Model labels:\", labels)\n",
    "else:\n",
    "    print(\"Labels not found in the model's configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_env)",
   "language": "python",
   "name": "bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
