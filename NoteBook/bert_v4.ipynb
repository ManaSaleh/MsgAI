{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 1: **Load the Dataset**\n",
    "We’ll start by loading the dataset from the CSV file (`smsDataLast.csv`) using `pandas`.\n",
    "\n",
    "### Explanation:\n",
    "- The dataset contains SMS messages and their corresponding categories (labels).\n",
    "- We’ll use `pandas` to load the data into a DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Data/rr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message Content</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>is_important</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dates</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samba.</td>\n",
       "      <td>تم خصم مبلغ ٥٠٫٠٠ من حساب ******٤٥٢١ في ٠٥-٠٥-...</td>\n",
       "      <td>['Money/Financial', 'Expense']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'amount': '٥٠٫٠٠', 'type': 'expense', 'accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607941</td>\n",
       "      <td>Your WhatsApp code is 614-968 but you can simp...</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>Dear Member, you have not redeemed any Neqaty ...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>عزيزي العميل، لقد مر 17 شهر و لم تقم باي عملية...</td>\n",
       "      <td>['Notification', 'Promotion']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606006</td>\n",
       "      <td>BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sender                                    Message Content  \\\n",
       "0  samba.  تم خصم مبلغ ٥٠٫٠٠ من حساب ******٤٥٢١ في ٠٥-٠٥-...   \n",
       "1  607941  Your WhatsApp code is 614-968 but you can simp...   \n",
       "2  neqaty  Dear Member, you have not redeemed any Neqaty ...   \n",
       "3  neqaty  عزيزي العميل، لقد مر 17 شهر و لم تقم باي عملية...   \n",
       "4  606006  BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...   \n",
       "\n",
       "                  category_labels  is_important  is_spam  \\\n",
       "0  ['Money/Financial', 'Expense']             1        0   \n",
       "1                       ['Other']             0        0   \n",
       "2    ['Promotion', 'Advertising']             0        1   \n",
       "3   ['Notification', 'Promotion']             0        1   \n",
       "4    ['Promotion', 'Advertising']             0        1   \n",
       "\n",
       "                                        transactions dates     category  \n",
       "0  {'amount': '٥٠٫٠٠', 'type': 'expense', 'accoun...   NaN    Financial  \n",
       "1                                                NaN   NaN        Other  \n",
       "2                                                NaN   NaN  Promotional  \n",
       "3                                                NaN   NaN  Promotional  \n",
       "4                                                NaN   NaN  Promotional  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6996 entries, 0 to 6995\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Sender           6996 non-null   object\n",
      " 1   Message Content  6996 non-null   object\n",
      " 2   category_labels  6996 non-null   object\n",
      " 3   is_important     6996 non-null   int64 \n",
      " 4   is_spam          6996 non-null   int64 \n",
      " 5   transactions     3053 non-null   object\n",
      " 6   dates            484 non-null    object\n",
      " 7   category         6996 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 437.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the columns and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the distribution of categories\n",
    "df.drop(columns='category_labels' , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 2: **Preprocess the Data**\n",
    "We’ll preprocess the data to prepare it for training. This includes:\n",
    "- Mapping categories to numerical labels.\n",
    "- Splitting the data into training and testing sets.\n",
    "\n",
    "### Explanation:\n",
    "- Text classification requires numerical labels, so we’ll convert the `Category` column to numerical values.\n",
    "- We’ll split the data into training and testing sets (e.g., 80% training, 20% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Financial', 'Other', 'Promotional', 'Telecommunications',\n",
       "       'Health', 'Services or Stores', 'Education', 'Governmental',\n",
       "       'Travel'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categories to numerical labels\n",
    "df['label'] = df['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " label\n",
      "1    2531\n",
      "5    1417\n",
      "4     685\n",
      "7     484\n",
      "2     201\n",
      "3     137\n",
      "0     129\n",
      "6       7\n",
      "8       5\n",
      "Name: count, dtype: int64\n",
      "Testing set class distribution:\n",
      " label\n",
      "1    634\n",
      "5    355\n",
      "4    171\n",
      "7    121\n",
      "2     50\n",
      "3     34\n",
      "0     32\n",
      "6      2\n",
      "8      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df[['Message Content', 'label']],  # Include both 'Message Content' and 'category'\n",
    "    test_size=0.2,  # 20% of the data for testing\n",
    "    random_state=42,  # For reproducibility\n",
    "    shuffle=True,  # Shuffle the data before splitting\n",
    "    stratify=df['category']  # Preserve the class distribution\n",
    ")\n",
    "\n",
    "# Check the distribution of categories in the training and testing sets\n",
    "print(\"Training set class distribution:\\n\", train_df['label'].value_counts())\n",
    "print(\"Testing set class distribution:\\n\", test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5596, 2)\n",
      "Testing data shape: (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Testing data shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>للدخول 1361 الرجاء إدخال الرمز</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>عميلنا العزيز\\nشكرا لاشتراكك، رقم برنامج الخدم...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>يوجد لديك عقد عمل جديد بانتظار مراجعتك واعتماد...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>عزيزي العميل: يسعدنا ان نقدم لكم أحدث تصاميم ب...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>Mobily Missed Call Notification Service. +9665...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>ضيوف الرحمن \\r\\nخدمتكم شرف .. وأمنكم واجبنا \\r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>مشتريات دولية عبر الانترنت\\nمن بطاقة:9394*\\nرق...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>شراء-POS\\r\\nبـ49 SAR\\r\\nمن مطعم مشوي\\r\\nمدى-اب...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>تم تنشيط المستفيد:شركة لدن للاستثمار</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>فصل الشتاء قادم، فاجعل الموسم سليم\\r\\nننصح بأخ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Message Content  label\n",
       "3093                     للدخول 1361 الرجاء إدخال الرمز      4\n",
       "1643  عميلنا العزيز\\nشكرا لاشتراكك، رقم برنامج الخدم...      5\n",
       "6382  يوجد لديك عقد عمل جديد بانتظار مراجعتك واعتماد...      7\n",
       "6609  عزيزي العميل: يسعدنا ان نقدم لكم أحدث تصاميم ب...      5\n",
       "4499  Mobily Missed Call Notification Service. +9665...      5\n",
       "...                                                 ...    ...\n",
       "2892  ضيوف الرحمن \\r\\nخدمتكم شرف .. وأمنكم واجبنا \\r...      2\n",
       "4470  مشتريات دولية عبر الانترنت\\nمن بطاقة:9394*\\nرق...      1\n",
       "6325  شراء-POS\\r\\nبـ49 SAR\\r\\nمن مطعم مشوي\\r\\nمدى-اب...      1\n",
       "6813               تم تنشيط المستفيد:شركة لدن للاستثمار      7\n",
       "3755  فصل الشتاء قادم، فاجعل الموسم سليم\\r\\nننصح بأخ...      3\n",
       "\n",
       "[5596 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 3: **Tokenize the Data**\n",
    "We’ll tokenize the text data using the `AutoTokenizer` from Hugging Face’s `transformers` library.\n",
    "\n",
    "### Explanation:\n",
    "- Tokenization converts text into numerical input that the model can understand.\n",
    "- We’ll use the `AutoTokenizer` for ModernBERT and ensure all sequences are padded/truncated to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Message Content\"], padding=\"max_length\", truncation=True, max_length=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization to the training and testing datasets\n",
    "train_dataset = train_df.apply(tokenize_function, axis=1)\n",
    "test_dataset = test_df.apply(tokenize_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized example: {'input_ids': [50281, 4467, 4467, 9211, 28337, 41147, 14821, 18, 9445, 6900, 23072, 10714, 96, 48914, 9211, 28337, 7427, 9445, 6900, 5843, 29620, 50282, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Check the tokenized output for the first example\n",
    "print(\"Tokenized example:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: **Test the Model on a Single Row**\n",
    "Before training, we’ll test the model on a single row to ensure it works.\n",
    "\n",
    "### Explanation:\n",
    "- We’ll load the ModernBERT model and pass a single tokenized input to it.\n",
    "- This helps verify that the model and tokenizer are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=len(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single row\n",
    "sample_input = tokenizer(train_df.iloc[0][\"Message Content\"], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=52)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted class\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "predicted_class = df['category'].unique()[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Financial\n",
      "Actual class: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Actual class:\", train_df.iloc[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: **Train the Model**\n",
    "We’ll train the model using the `Trainer` API from Hugging Face.\n",
    "\n",
    "### Explanation:\n",
    "- The `Trainer` API simplifies the training process by handling training loops, evaluation, and logging.\n",
    "- We’ll define training arguments (e.g., learning rate, batch size) and train the model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b801b9c1723540f0b083c6dcce64f96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436283a2b9344477aee8eeaa00e0dec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/transformers/training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    logging_strategy=\"epoch\",     # Log metrics at the end of each epoch\n",
    "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",         # Directory for logs\n",
    "    report_to=\"all\",              # Log to all available trackers (e.g., TensorBoard, W&B)\n",
    "    load_best_model_at_end=True,  # Required for EarlyStoppingCallback\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss to determine the best model\n",
    "    greater_is_better=False,      # Lower validation loss is better\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop if validation loss doesn't improve for 3 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2196' max='7320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2196/7320 57:44 < 2:14:51, 0.63 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.659716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.436465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.421289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.439947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>0.465892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.612107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2196, training_loss=0.27909195488267907, metrics={'train_runtime': 3466.7939, 'train_samples_per_second': 33.737, 'train_steps_per_second': 2.111, 'total_flos': 1214392109164416.0, 'train_loss': 0.27909195488267907, 'epoch': 6.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 6: **Evaluate the Model**\n",
    "After training, we’ll evaluate the model on the test set.\n",
    "\n",
    "### Explanation:\n",
    "- We’ll use the `Trainer` API to evaluate the model’s performance on the test dataset.\n",
    "- Metrics like accuracy, precision, recall, and F1 score can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.42128902673721313, 'eval_runtime': 32.9424, 'eval_samples_per_second': 42.498, 'eval_steps_per_second': 5.312, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "         Education       0.64      0.66      0.65        32\n",
      "         Financial       1.00      0.96      0.98       634\n",
      "      Governmental       0.68      0.60      0.64        50\n",
      "            Health       0.92      0.35      0.51        34\n",
      "             Other       0.66      0.88      0.75       171\n",
      "       Promotional       0.86      0.92      0.89       355\n",
      "Services or Stores       1.00      0.50      0.67         2\n",
      "Telecommunications       0.83      0.61      0.70       121\n",
      "            Travel       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.88      1400\n",
      "         macro avg       0.73      0.61      0.64      1400\n",
      "      weighted avg       0.88      0.88      0.87      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get predictions for the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract predicted labels\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# True labels\n",
    "true_labels = test_dataset['label']\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get unique classes in true_labels\n",
    "unique_classes = np.unique(true_labels)\n",
    "\n",
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "\n",
    "# Generate classification report with actual category names\n",
    "target_names = [label_mapping[i] for i in unique_classes]  # Use category names instead of \"Class X\"\n",
    "\n",
    "class_report = classification_report(\n",
    "    true_labels, \n",
    "    predicted_labels, \n",
    "    target_names=target_names, \n",
    "    labels=unique_classes,\n",
    "    zero_division=0  # Suppress warnings by setting precision to 0 for undefined cases\n",
    ")\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 7: **Save the Model**\n",
    "We’ll save the fine-tuned model for future use.\n",
    "\n",
    "### Explanation:\n",
    "- Saving the model allows us to reuse it without retraining.\n",
    "- We’ll save both the model and tokenizer to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Models/fine-tuned-modernbert_v4/tokenizer_config.json',\n",
       " '../Models/fine-tuned-modernbert_v4/special_tokens_map.json',\n",
       " '../Models/fine-tuned-modernbert_v4/tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"../Models/fine-tuned-modernbert_v4\")\n",
    "tokenizer.save_pretrained(\"../Models/fine-tuned-modernbert_v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 8: **Load the Fine-Tuned Model**\n",
    "To load the fine-tuned model later:\n",
    "\n",
    "### Explanation:\n",
    "- We’ll load the saved model and tokenizer for inference or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../Models/fine-tuned-modernbert_v4\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../Models/fine-tuned-modernbert_v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping (ID to Label):\n",
      "ID: 0, Label: LABEL_0\n",
      "ID: 1, Label: LABEL_1\n",
      "ID: 2, Label: LABEL_2\n",
      "ID: 3, Label: LABEL_3\n",
      "ID: 4, Label: LABEL_4\n",
      "ID: 5, Label: LABEL_5\n",
      "ID: 6, Label: LABEL_6\n",
      "ID: 7, Label: LABEL_7\n",
      "ID: 8, Label: LABEL_8\n"
     ]
    }
   ],
   "source": [
    "label_mapping = model.config.id2label\n",
    "\n",
    "print(\"Label Mapping (ID to Label):\")\n",
    "for idx, label in label_mapping.items():\n",
    "    print(f\"ID: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping (ID to Category Name):\n",
      "ID: 0, Category: Education\n",
      "ID: 1, Category: Financial\n",
      "ID: 2, Category: Governmental\n",
      "ID: 3, Category: Health\n",
      "ID: 4, Category: Other\n",
      "ID: 5, Category: Promotional\n",
      "ID: 6, Category: Services or Stores\n",
      "ID: 7, Category: Telecommunications\n",
      "ID: 8, Category: Travel\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "print(\"Label Mapping (ID to Category Name):\")\n",
    "for idx, category in label_mapping.items():\n",
    "    print(f\"ID: {idx}, Category: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_env)",
   "language": "python",
   "name": "bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
