{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 1: **Load the Dataset**\n",
    "Weâ€™ll start by loading the dataset from the CSV file (`smsDataLast.csv`) using `pandas`.\n",
    "\n",
    "### Explanation:\n",
    "- The dataset contains SMS messages and their corresponding categories (labels).\n",
    "- Weâ€™ll use `pandas` to load the data into a DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Data/rr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Message Content</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>is_important</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dates</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samba.</td>\n",
       "      <td>ØªÙ… Ø®ØµÙ… Ù…Ø¨Ù„Øº Ù¥Ù Ù«Ù Ù  Ù…Ù† Ø­Ø³Ø§Ø¨ ******Ù¤Ù¥Ù¢Ù¡ ÙÙŠ Ù Ù¥-Ù Ù¥-...</td>\n",
       "      <td>['Money/Financial', 'Expense']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'amount': 'Ù¥Ù Ù«Ù Ù ', 'type': 'expense', 'accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>607941</td>\n",
       "      <td>Your WhatsApp code is 614-968 but you can simp...</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>Dear Member, you have not redeemed any Neqaty ...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neqaty</td>\n",
       "      <td>Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„ØŒ Ù„Ù‚Ø¯ Ù…Ø± 17 Ø´Ù‡Ø± Ùˆ Ù„Ù… ØªÙ‚Ù… Ø¨Ø§ÙŠ Ø¹Ù…Ù„ÙŠØ©...</td>\n",
       "      <td>['Notification', 'Promotion']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606006</td>\n",
       "      <td>BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...</td>\n",
       "      <td>['Promotion', 'Advertising']</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sender                                    Message Content  \\\n",
       "0  samba.  ØªÙ… Ø®ØµÙ… Ù…Ø¨Ù„Øº Ù¥Ù Ù«Ù Ù  Ù…Ù† Ø­Ø³Ø§Ø¨ ******Ù¤Ù¥Ù¢Ù¡ ÙÙŠ Ù Ù¥-Ù Ù¥-...   \n",
       "1  607941  Your WhatsApp code is 614-968 but you can simp...   \n",
       "2  neqaty  Dear Member, you have not redeemed any Neqaty ...   \n",
       "3  neqaty  Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„ØŒ Ù„Ù‚Ø¯ Ù…Ø± 17 Ø´Ù‡Ø± Ùˆ Ù„Ù… ØªÙ‚Ù… Ø¨Ø§ÙŠ Ø¹Ù…Ù„ÙŠØ©...   \n",
       "4  606006  BIG SAVINGS! Now get 200 Mobily Minutes, 200 M...   \n",
       "\n",
       "                  category_labels  is_important  is_spam  \\\n",
       "0  ['Money/Financial', 'Expense']             1        0   \n",
       "1                       ['Other']             0        0   \n",
       "2    ['Promotion', 'Advertising']             0        1   \n",
       "3   ['Notification', 'Promotion']             0        1   \n",
       "4    ['Promotion', 'Advertising']             0        1   \n",
       "\n",
       "                                        transactions dates     category  \n",
       "0  {'amount': 'Ù¥Ù Ù«Ù Ù ', 'type': 'expense', 'accoun...   NaN    Financial  \n",
       "1                                                NaN   NaN        Other  \n",
       "2                                                NaN   NaN  Promotional  \n",
       "3                                                NaN   NaN  Promotional  \n",
       "4                                                NaN   NaN  Promotional  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6996 entries, 0 to 6995\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Sender           6996 non-null   object\n",
      " 1   Message Content  6996 non-null   object\n",
      " 2   category_labels  6996 non-null   object\n",
      " 3   is_important     6996 non-null   int64 \n",
      " 4   is_spam          6996 non-null   int64 \n",
      " 5   transactions     3053 non-null   object\n",
      " 6   dates            484 non-null    object\n",
      " 7   category         6996 non-null   object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 437.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the columns and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check the distribution of categories\n",
    "df.drop(columns='category_labels' , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 2: **Preprocess the Data**\n",
    "Weâ€™ll preprocess the data to prepare it for training. This includes:\n",
    "- Mapping categories to numerical labels.\n",
    "- Splitting the data into training and testing sets.\n",
    "\n",
    "### Explanation:\n",
    "- Text classification requires numerical labels, so weâ€™ll convert the `Category` column to numerical values.\n",
    "- Weâ€™ll split the data into training and testing sets (e.g., 80% training, 20% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Financial', 'Other', 'Promotional', 'Telecommunications',\n",
       "       'Health', 'Services or Stores', 'Education', 'Governmental',\n",
       "       'Travel'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categories to numerical labels\n",
    "df['label'] = df['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      " label\n",
      "1    2531\n",
      "5    1417\n",
      "4     685\n",
      "7     484\n",
      "2     201\n",
      "3     137\n",
      "0     129\n",
      "6       7\n",
      "8       5\n",
      "Name: count, dtype: int64\n",
      "Testing set class distribution:\n",
      " label\n",
      "1    634\n",
      "5    355\n",
      "4    171\n",
      "7    121\n",
      "2     50\n",
      "3     34\n",
      "0     32\n",
      "6      2\n",
      "8      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df[['Message Content', 'label']],  # Include both 'Message Content' and 'category'\n",
    "    test_size=0.2,  # 20% of the data for testing\n",
    "    random_state=42,  # For reproducibility\n",
    "    shuffle=True,  # Shuffle the data before splitting\n",
    "    stratify=df['category']  # Preserve the class distribution\n",
    ")\n",
    "\n",
    "# Check the distribution of categories in the training and testing sets\n",
    "print(\"Training set class distribution:\\n\", train_df['label'].value_counts())\n",
    "print(\"Testing set class distribution:\\n\", test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5596, 2)\n",
      "Testing data shape: (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Testing data shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>Ù„Ù„Ø¯Ø®ÙˆÙ„ 1361 Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù…Ø²</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>Ø¹Ù…ÙŠÙ„Ù†Ø§ Ø§Ù„Ø¹Ø²ÙŠØ²\\nØ´ÙƒØ±Ø§ Ù„Ø§Ø´ØªØ±Ø§ÙƒÙƒØŒ Ø±Ù‚Ù… Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø®Ø¯Ù…...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6382</th>\n",
       "      <td>ÙŠÙˆØ¬Ø¯ Ù„Ø¯ÙŠÙƒ Ø¹Ù‚Ø¯ Ø¹Ù…Ù„ Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø±Ø§Ø¬Ø¹ØªÙƒ ÙˆØ§Ø¹ØªÙ…Ø§Ø¯...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„: ÙŠØ³Ø¹Ø¯Ù†Ø§ Ø§Ù† Ù†Ù‚Ø¯Ù… Ù„ÙƒÙ… Ø£Ø­Ø¯Ø« ØªØµØ§Ù…ÙŠÙ… Ø¨...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>Mobily Missed Call Notification Service. +9665...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>Ø¶ÙŠÙˆÙ Ø§Ù„Ø±Ø­Ù…Ù† \\r\\nØ®Ø¯Ù…ØªÙƒÙ… Ø´Ø±Ù .. ÙˆØ£Ù…Ù†ÙƒÙ… ÙˆØ§Ø¬Ø¨Ù†Ø§ \\r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>Ù…Ø´ØªØ±ÙŠØ§Øª Ø¯ÙˆÙ„ÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ø§Ù†ØªØ±Ù†Øª\\nÙ…Ù† Ø¨Ø·Ø§Ù‚Ø©:9394*\\nØ±Ù‚...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>Ø´Ø±Ø§Ø¡-POS\\r\\nØ¨Ù€49 SAR\\r\\nÙ…Ù† Ù…Ø·Ø¹Ù… Ù…Ø´ÙˆÙŠ\\r\\nÙ…Ø¯Ù‰-Ø§Ø¨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>ØªÙ… ØªÙ†Ø´ÙŠØ· Ø§Ù„Ù…Ø³ØªÙÙŠØ¯:Ø´Ø±ÙƒØ© Ù„Ø¯Ù† Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>ÙØµÙ„ Ø§Ù„Ø´ØªØ§Ø¡ Ù‚Ø§Ø¯Ù…ØŒ ÙØ§Ø¬Ø¹Ù„ Ø§Ù„Ù…ÙˆØ³Ù… Ø³Ù„ÙŠÙ…\\r\\nÙ†Ù†ØµØ­ Ø¨Ø£Ø®...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5596 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Message Content  label\n",
       "3093                     Ù„Ù„Ø¯Ø®ÙˆÙ„ 1361 Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù…Ø²      4\n",
       "1643  Ø¹Ù…ÙŠÙ„Ù†Ø§ Ø§Ù„Ø¹Ø²ÙŠØ²\\nØ´ÙƒØ±Ø§ Ù„Ø§Ø´ØªØ±Ø§ÙƒÙƒØŒ Ø±Ù‚Ù… Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø®Ø¯Ù…...      5\n",
       "6382  ÙŠÙˆØ¬Ø¯ Ù„Ø¯ÙŠÙƒ Ø¹Ù‚Ø¯ Ø¹Ù…Ù„ Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø±Ø§Ø¬Ø¹ØªÙƒ ÙˆØ§Ø¹ØªÙ…Ø§Ø¯...      7\n",
       "6609  Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ„: ÙŠØ³Ø¹Ø¯Ù†Ø§ Ø§Ù† Ù†Ù‚Ø¯Ù… Ù„ÙƒÙ… Ø£Ø­Ø¯Ø« ØªØµØ§Ù…ÙŠÙ… Ø¨...      5\n",
       "4499  Mobily Missed Call Notification Service. +9665...      5\n",
       "...                                                 ...    ...\n",
       "2892  Ø¶ÙŠÙˆÙ Ø§Ù„Ø±Ø­Ù…Ù† \\r\\nØ®Ø¯Ù…ØªÙƒÙ… Ø´Ø±Ù .. ÙˆØ£Ù…Ù†ÙƒÙ… ÙˆØ§Ø¬Ø¨Ù†Ø§ \\r...      2\n",
       "4470  Ù…Ø´ØªØ±ÙŠØ§Øª Ø¯ÙˆÙ„ÙŠØ© Ø¹Ø¨Ø± Ø§Ù„Ø§Ù†ØªØ±Ù†Øª\\nÙ…Ù† Ø¨Ø·Ø§Ù‚Ø©:9394*\\nØ±Ù‚...      1\n",
       "6325  Ø´Ø±Ø§Ø¡-POS\\r\\nØ¨Ù€49 SAR\\r\\nÙ…Ù† Ù…Ø·Ø¹Ù… Ù…Ø´ÙˆÙŠ\\r\\nÙ…Ø¯Ù‰-Ø§Ø¨...      1\n",
       "6813               ØªÙ… ØªÙ†Ø´ÙŠØ· Ø§Ù„Ù…Ø³ØªÙÙŠØ¯:Ø´Ø±ÙƒØ© Ù„Ø¯Ù† Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±      7\n",
       "3755  ÙØµÙ„ Ø§Ù„Ø´ØªØ§Ø¡ Ù‚Ø§Ø¯Ù…ØŒ ÙØ§Ø¬Ø¹Ù„ Ø§Ù„Ù…ÙˆØ³Ù… Ø³Ù„ÙŠÙ…\\r\\nÙ†Ù†ØµØ­ Ø¨Ø£Ø®...      3\n",
       "\n",
       "[5596 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 3: **Tokenize the Data**\n",
    "Weâ€™ll tokenize the text data using the `AutoTokenizer` from Hugging Faceâ€™s `transformers` library.\n",
    "\n",
    "### Explanation:\n",
    "- Tokenization converts text into numerical input that the model can understand.\n",
    "- Weâ€™ll use the `AutoTokenizer` for ModernBERT and ensure all sequences are padded/truncated to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Message Content\"], padding=\"max_length\", truncation=True, max_length=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization to the training and testing datasets\n",
    "train_dataset = train_df.apply(tokenize_function, axis=1)\n",
    "test_dataset = test_df.apply(tokenize_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized example: {'input_ids': [50281, 4467, 4467, 9211, 28337, 41147, 14821, 18, 9445, 6900, 23072, 10714, 96, 48914, 9211, 28337, 7427, 9445, 6900, 5843, 29620, 50282, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Check the tokenized output for the first example\n",
    "print(\"Tokenized example:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: **Test the Model on a Single Row**\n",
    "Before training, weâ€™ll test the model on a single row to ensure it works.\n",
    "\n",
    "### Explanation:\n",
    "- Weâ€™ll load the ModernBERT model and pass a single tokenized input to it.\n",
    "- This helps verify that the model and tokenizer are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=len(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single row\n",
    "sample_input = tokenizer(train_df.iloc[0][\"Message Content\"], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=52)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted class\n",
    "predicted_class_id = outputs.logits.argmax().item()\n",
    "predicted_class = df['category'].unique()[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Financial\n",
      "Actual class: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Actual class:\", train_df.iloc[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: **Train the Model**\n",
    "Weâ€™ll train the model using the `Trainer` API from Hugging Face.\n",
    "\n",
    "### Explanation:\n",
    "- The `Trainer` API simplifies the training process by handling training loops, evaluation, and logging.\n",
    "- Weâ€™ll define training arguments (e.g., learning rate, batch size) and train the model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b801b9c1723540f0b083c6dcce64f96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436283a2b9344477aee8eeaa00e0dec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mana-saleh/anaconda3/envs/bert_env/lib/python3.12/site-packages/transformers/training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    logging_strategy=\"epoch\",     # Log metrics at the end of each epoch\n",
    "    save_strategy=\"epoch\",        # Save the model at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",         # Directory for logs\n",
    "    report_to=\"all\",              # Log to all available trackers (e.g., TensorBoard, W&B)\n",
    "    load_best_model_at_end=True,  # Required for EarlyStoppingCallback\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss to determine the best model\n",
    "    greater_is_better=False,      # Lower validation loss is better\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop if validation loss doesn't improve for 3 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2196' max='7320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2196/7320 57:44 < 2:14:51, 0.63 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.659716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.436465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.421289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.439947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>0.465892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.612107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2196, training_loss=0.27909195488267907, metrics={'train_runtime': 3466.7939, 'train_samples_per_second': 33.737, 'train_steps_per_second': 2.111, 'total_flos': 1214392109164416.0, 'train_loss': 0.27909195488267907, 'epoch': 6.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 6: **Evaluate the Model**\n",
    "After training, weâ€™ll evaluate the model on the test set.\n",
    "\n",
    "### Explanation:\n",
    "- Weâ€™ll use the `Trainer` API to evaluate the modelâ€™s performance on the test dataset.\n",
    "- Metrics like accuracy, precision, recall, and F1 score can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.42128902673721313, 'eval_runtime': 32.9424, 'eval_samples_per_second': 42.498, 'eval_steps_per_second': 5.312, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "         Education       0.64      0.66      0.65        32\n",
      "         Financial       1.00      0.96      0.98       634\n",
      "      Governmental       0.68      0.60      0.64        50\n",
      "            Health       0.92      0.35      0.51        34\n",
      "             Other       0.66      0.88      0.75       171\n",
      "       Promotional       0.86      0.92      0.89       355\n",
      "Services or Stores       1.00      0.50      0.67         2\n",
      "Telecommunications       0.83      0.61      0.70       121\n",
      "            Travel       0.00      0.00      0.00         1\n",
      "\n",
      "          accuracy                           0.88      1400\n",
      "         macro avg       0.73      0.61      0.64      1400\n",
      "      weighted avg       0.88      0.88      0.87      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get predictions for the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Extract predicted labels\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# True labels\n",
    "true_labels = test_dataset['label']\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get unique classes in true_labels\n",
    "unique_classes = np.unique(true_labels)\n",
    "\n",
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "\n",
    "# Generate classification report with actual category names\n",
    "target_names = [label_mapping[i] for i in unique_classes]  # Use category names instead of \"Class X\"\n",
    "\n",
    "class_report = classification_report(\n",
    "    true_labels, \n",
    "    predicted_labels, \n",
    "    target_names=target_names, \n",
    "    labels=unique_classes,\n",
    "    zero_division=0  # Suppress warnings by setting precision to 0 for undefined cases\n",
    ")\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 7: **Save the Model**\n",
    "Weâ€™ll save the fine-tuned model for future use.\n",
    "\n",
    "### Explanation:\n",
    "- Saving the model allows us to reuse it without retraining.\n",
    "- Weâ€™ll save both the model and tokenizer to a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Models/fine-tuned-modernbert_v4/tokenizer_config.json',\n",
       " '../Models/fine-tuned-modernbert_v4/special_tokens_map.json',\n",
       " '../Models/fine-tuned-modernbert_v4/tokenizer.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"../Models/fine-tuned-modernbert_v4\")\n",
    "tokenizer.save_pretrained(\"../Models/fine-tuned-modernbert_v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 8: **Load the Fine-Tuned Model**\n",
    "To load the fine-tuned model later:\n",
    "\n",
    "### Explanation:\n",
    "- Weâ€™ll load the saved model and tokenizer for inference or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../Models/fine-tuned-modernbert_v4\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../Models/fine-tuned-modernbert_v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping (ID to Label):\n",
      "ID: 0, Label: LABEL_0\n",
      "ID: 1, Label: LABEL_1\n",
      "ID: 2, Label: LABEL_2\n",
      "ID: 3, Label: LABEL_3\n",
      "ID: 4, Label: LABEL_4\n",
      "ID: 5, Label: LABEL_5\n",
      "ID: 6, Label: LABEL_6\n",
      "ID: 7, Label: LABEL_7\n",
      "ID: 8, Label: LABEL_8\n"
     ]
    }
   ],
   "source": [
    "label_mapping = model.config.id2label\n",
    "\n",
    "print(\"Label Mapping (ID to Label):\")\n",
    "for idx, label in label_mapping.items():\n",
    "    print(f\"ID: {idx}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping (ID to Category Name):\n",
      "ID: 0, Category: Education\n",
      "ID: 1, Category: Financial\n",
      "ID: 2, Category: Governmental\n",
      "ID: 3, Category: Health\n",
      "ID: 4, Category: Other\n",
      "ID: 5, Category: Promotional\n",
      "ID: 6, Category: Services or Stores\n",
      "ID: 7, Category: Telecommunications\n",
      "ID: 8, Category: Travel\n"
     ]
    }
   ],
   "source": [
    "label_mapping = dict(enumerate(df['category'].astype('category').cat.categories))\n",
    "print(\"Label Mapping (ID to Category Name):\")\n",
    "for idx, category in label_mapping.items():\n",
    "    print(f\"ID: {idx}, Category: {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_env)",
   "language": "python",
   "name": "bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
